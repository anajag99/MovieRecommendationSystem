{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8fa677-376f-4629-a09d-ac088a4dad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb749985-090e-4290-86ec-3d286b46b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries if not already installed\n",
    "!pip install surprise scikit-surprise xgboost tensorflow keras nltk scikit-learn pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a9abe-177a-41be-8942-097a455e357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "import nltk\n",
    "\n",
    "from surprise import Dataset, Reader, SVD, NMF, accuracy\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# For visualization\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26101be5-e5e8-4d4b-9ecd-835afd3799ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MovieLens Dataset\n",
    "df_ratings = pd.read_csv(\"ratings.csv\")\n",
    "df_movies = pd.read_csv(\"movies.csv\")\n",
    "\n",
    "# Merge ratings with movies for exploration\n",
    "df = df_ratings.merge(df_movies, on=\"movieId\")\n",
    "\n",
    "# Display dataset info\n",
    "print(df.head())\n",
    "\n",
    "# Check missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Basic stats\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ddbed-a550-4518-93d6-b72537fd7e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ratings to binary (1 = liked, 0 = not liked)\n",
    "df[\"liked\"] = np.where(df[\"rating\"] >= 3.5, 1, 0)\n",
    "\n",
    "# Split dataset into training and testing\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Surprise Reader\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(df_ratings[[\"userId\", \"movieId\", \"rating\"]], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9a0aa5-3e3c-4e5d-a8dc-e5ca13fb77d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Matrix Factorization Models\n",
    "#Singular Value Decomposition (SVD)\n",
    "\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "predictions_svd = svd.test(testset)\n",
    "\n",
    "# Evaluate SVD\n",
    "rmse_svd = accuracy.rmse(predictions_svd)\n",
    "mae_svd = accuracy.mae(predictions_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ce6f0-d080-49db-9783-671c3d7fad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Negative Matrix Factorization (NMF)\n",
    "\n",
    "nmf = NMF()\n",
    "nmf.fit(trainset)\n",
    "predictions_nmf = nmf.test(testset)\n",
    "\n",
    "# Evaluate NMF\n",
    "rmse_nmf = accuracy.rmse(predictions_nmf)\n",
    "mae_nmf = accuracy.mae(predictions_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62796dd5-d808-40f5-8fea-9143aedfc1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train XGBoost Model\n",
    "\n",
    "# Prepare data for XGBoost\n",
    "features = df[[\"userId\", \"movieId\"]]\n",
    "labels = df[\"rating\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, learning_rate=0.1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7466d4f7-f19e-4de0-abbc-22bdf55ea915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Collaborative Filtering (NCF - Deep Learning)\n",
    "\n",
    "# Define embedding size\n",
    "embedding_size = 50\n",
    "\n",
    "# User and Movie Input Layers\n",
    "user_input = Input(shape=(1,))\n",
    "movie_input = Input(shape=(1,))\n",
    "\n",
    "user_embedding = Embedding(input_dim=df[\"userId\"].nunique()+1, output_dim=embedding_size)(user_input)\n",
    "movie_embedding = Embedding(input_dim=df[\"movieId\"].nunique()+1, output_dim=embedding_size)(movie_input)\n",
    "\n",
    "user_vec = Flatten()(user_embedding)\n",
    "movie_vec = Flatten()(movie_embedding)\n",
    "\n",
    "concat = Concatenate()([user_vec, movie_vec])\n",
    "dense = Dense(128, activation=\"relu\")(concat)\n",
    "dense = Dense(64, activation=\"relu\")(dense)\n",
    "dense = Dense(32, activation=\"relu\")(dense)\n",
    "output = Dense(1, activation=\"sigmoid\")(dense)\n",
    "\n",
    "# Compile model\n",
    "ncf_model = Model([user_input, movie_input], output)\n",
    "ncf_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "ncf_model.fit([train[\"userId\"], train[\"movieId\"]], train[\"liked\"], epochs=5, batch_size=256)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy_ncf = ncf_model.evaluate([test[\"userId\"], test[\"movieId\"]], test[\"liked\"])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc672c8a-2030-4a6f-b762-ca6d80f62f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Content-Based Filtering (TF-IDF)\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix = tfidf.fit_transform(df_movies[\"genres\"])\n",
    "\n",
    "# Nearest Neighbors Model\n",
    "nn_model = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn_model.fit(tfidf_matrix)\n",
    "\n",
    "# Function to recommend movies\n",
    "def recommend_movies(movie_title, n=5):\n",
    "    idx = df_movies[df_movies[\"title\"] == movie_title].index[0]\n",
    "    distances, indices = nn_model.kneighbors(tfidf_matrix[idx], n_neighbors=n+1)\n",
    "    \n",
    "    print(\"Recommended Movies:\")\n",
    "    for i in indices.flatten()[1:]:\n",
    "        print(df_movies.iloc[i][\"title\"])\n",
    "\n",
    "# Example Recommendation\n",
    "recommend_movies(\"Toy Story (1995)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
